{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discription: Fashion Mnist 图像分类"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T10:55:40.210681Z",
     "start_time": "2025-05-26T10:54:53.724610Z"
    }
   },
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T10:55:47.201581Z",
     "start_time": "2025-05-26T10:55:45.605387Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.cuda.is_available())",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "\t'''\n",
    "    定义Dataset:\n",
    "    - 用于加载训练和测试数据，请勿改动\n",
    "    - 返回一张图片(3维Tensor)以及对应的标签(0-9)\n",
    "    '''\n",
    "\n",
    "\tdef __init__(self, datadir, transform, is_train=True):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.datadir = datadir\n",
    "\t\tself.img, self.label = self.load_data(self.datadir, is_train=is_train)\n",
    "\t\tself.len_data = len(self.img)\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\treturn self.transform(self.img[index]), self.label[index]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.len_data\n",
    "\n",
    "\tdef load_data(self, datadir, is_train):\n",
    "\t\tdirname = os.path.join(datadir)\n",
    "\t\tfiles = ['train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n",
    "\t\t\t\t 't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz']\n",
    "\n",
    "\t\tpaths = []\n",
    "\t\tfor fname in files:\n",
    "\t\t\tpaths.append(os.path.join(dirname, fname))\n",
    "\t\tif is_train:\n",
    "\n",
    "\t\t\twith gzip.open(paths[0], 'rb') as lbpath:\n",
    "\t\t\t\tlabel = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\t\t\twith gzip.open(paths[1], 'rb') as imgpath:\n",
    "\t\t\t\timg = np.frombuffer(imgpath.read(), np.uint8,\n",
    "\t\t\t\t\t\t\t\t\toffset=16).reshape(len(label), 28, 28)\n",
    "\t\telse:\n",
    "\t\t\twith gzip.open(paths[2], 'rb') as lbpath:\n",
    "\t\t\t\tlabel = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "\t\t\twith gzip.open(paths[3], 'rb') as imgpath:\n",
    "\t\t\t\timg = np.frombuffer(imgpath.read(), np.uint8,\n",
    "\t\t\t\t\t\t\t\t\toffset=16).reshape(len(label), 28, 28)\n",
    "\t\treturn img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMnistModel(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\t'''\n",
    "        ***********请在此写入你的代码**********\n",
    "        定义模型\n",
    "        '''\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.conv1 = nn.Conv2d(1, 6, 5)\n",
    "\t\tself.pool1 = nn.MaxPool2d(2, 2)\n",
    "\t\tself.conv2 = nn.Conv2d(6, 16, 3)\n",
    "\t\tself.pool2 = nn.MaxPool2d(2, 2)\n",
    "\t\tself.linear1 = nn.Linear(16 * 5 * 5, 64)\n",
    "\t\tself.linear2 = nn.Linear(64, 10)\n",
    "\t\tself.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "def forward(self, x):\n",
    "\t'''\n",
    "    *********请在此处输入你的代码*********\n",
    "    输入：input, 它的size是(batch_size, img_c, img_h, img_w)\n",
    "    输出（返回值）：output(预测值)，hidden(隐藏层的值)\n",
    "        * output的size是(batch_size, num_label)\n",
    "\n",
    "    定义模型函数：\n",
    "        * 将输入经过卷积层和激活函数\n",
    "        * 使用pooling降低通道数\n",
    "        * 对卷积层的输出做适当的维度变换\n",
    "        * 用线性层将output映射到num_label的维度上\n",
    "        * 返回output\n",
    "    '''\n",
    "\tx = self.conv1(x)\n",
    "\tx = self.relu(x)\n",
    "\tx = self.pool1(x)\n",
    "\n",
    "\tx = self.conv2(x)\n",
    "\tx = self.relu(x)\n",
    "\tx = self.pool2(x)\n",
    "\n",
    "\tx = x.flatten(1)\n",
    "\n",
    "\tx = self.linear1(x)\n",
    "\tx = self.relu(x)\n",
    "\n",
    "\tx = self.linear2(x)\n",
    "\treturn x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "\tdef __init__(self):\n",
    "\t\t'''\n",
    "        创建模型和优化器，设置模型超参数\n",
    "        * 参数\n",
    "            * learning_rate\n",
    "            * epoches\n",
    "            * model_save_path\n",
    "            * device: cuda or cpu\n",
    "        * 模型\n",
    "            * 创建FashionMnistModel的实例，命名为model\n",
    "            * 定义optimizer\n",
    "            * 定义loss function\n",
    "        '''\n",
    "\t\tself.lr = 0.01\n",
    "\t\tself.epoches = 20\n",
    "\t\tself.model_save_path = './model'\n",
    "\t\t# 指定训练的device，优先使用GPU，GPU不可用时加载CPU\n",
    "\t\tself.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\t\tself.model = FashionMnistModel().to(self.device)\n",
    "\t\tself.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\t\tself.loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "\tdef _save_model(self, epoch):\n",
    "\t\t\"\"\"\n",
    "        保存模型，用于训练时保存指定epoch的模型\n",
    "        \"\"\"\n",
    "\t\tprint('[INFO] Saving to %s/%s.pth' % (self.model_save_path, epoch))\n",
    "\t\ttorch.save(self.model.state_dict(), '%s/%s.pth' % (self.model_save_path, epoch))\n",
    "\n",
    "\tdef _load_model(self, epoch):\n",
    "\t\t\"\"\"\n",
    "        加载模型，用于加载指定epoch的模型。\n",
    "        目前代码中没有用到。\n",
    "        可以在训练到一半但中断了之后，自行修改代码，从最近的epoch加载，然后继续训练，以节省时间。\n",
    "        或者训练完毕后，下次再跑程序，就直接加载模型，省去训练时间。\n",
    "        \"\"\"\n",
    "\t\tprint('[INFO] Loading from %s_%s.pth' % (self.model_save_path, epoch))\n",
    "\t\tself.model.load_state_dict(torch.load('%s/%s.pth' % (self.model_save_path, epoch), map_location=self.device))\n",
    "\n",
    "\tdef train(self, train_loader, test_loader):\n",
    "\t\t'''\n",
    "        训练函数\n",
    "        '''\n",
    "\n",
    "\t\tfor epoch in range(self.epoches):\n",
    "\t\t\tloss_list = []\n",
    "\t\t\tfor batch_idx, (data, target) in enumerate(train_loader):\n",
    "\t\t\t\tdata, target = data.to(self.device), target.long().to(self.device)\n",
    "\t\t\t\tself.optimizer.zero_grad()\n",
    "\t\t\t\toutput = self.model(data)\n",
    "\t\t\t\tloss = self.loss_function(output, target)\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\tself.optimizer.step()\n",
    "\t\t\t\tloss_list.append(loss.item())\n",
    "\t\t\t\tif batch_idx % 50 == 0:\n",
    "\t\t\t\t\tprint('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "\t\t\t\t\t\tepoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "\t\t\t\t\t\t\t   100. * batch_idx / len(train_loader), loss.item()))\n",
    "\t\t\tself.test(test_loader)\n",
    "\t\t\t# 保存模型参数\n",
    "\t\t\tif (epoch + 1) % 5 == 0:\n",
    "\t\t\t\tself._save_model(epoch + 1)\n",
    "\n",
    "\tdef test(self, test_loader):\n",
    "\t\t'''\n",
    "        检验模型测试集上的效果\n",
    "        '''\n",
    "\n",
    "\t\ttest_loss = 0\n",
    "\t\tcorrect = 0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor data, target in test_loader:\n",
    "\t\t\t\tdata, target = data.to(self.device), target.long().to(self.device)\n",
    "\t\t\t\toutput = self.model(data)\n",
    "\t\t\t\ttest_loss += self.loss_function(output, target).item()  # sum up batch loss\n",
    "\t\t\t\tpred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "\t\t\t\tcorrect += pred.eq(target.view_as(pred)).sum().item()\n",
    "\t\ttest_loss /= len(test_loader.dataset)\n",
    "\t\tprint('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "\t\t\ttest_loss, correct, len(test_loader.dataset),\n",
    "\t\t\t100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义data loader\n",
    "train_dataset = FashionDataset('data',\n",
    "\t\t\t\t\t\t\t   transform=transforms.Compose([\n",
    "\t\t\t\t\t\t\t\t   transforms.ToTensor(),\n",
    "\t\t\t\t\t\t\t\t   transforms.Normalize((0.1307,), (0.3081,))\n",
    "\t\t\t\t\t\t\t   ])\n",
    "\t\t\t\t\t\t\t   )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=320, shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataset = FashionDataset('data',\n",
    "\t\t\t\t\t\t\t  transform=transforms.Compose([\n",
    "\t\t\t\t\t\t\t\t  transforms.ToTensor(),\n",
    "\t\t\t\t\t\t\t\t  transforms.Normalize((0.1307,), (0.3081,))\n",
    "\t\t\t\t\t\t\t  ]),\n",
    "\t\t\t\t\t\t\t  is_train=False\n",
    "\t\t\t\t\t\t\t  )\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.411721\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.657743\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.458249\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.509745\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 7977/10000 (80%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.554021\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.452995\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.399422\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.451465\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 8273/10000 (83%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.583947\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.377678\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.315062\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.388187\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 7774/10000 (78%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.671110\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.485531\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.635712\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.458330\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 8259/10000 (83%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.387138\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.450008\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.424449\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.472354\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 7947/10000 (79%)\n",
      "\n",
      "[INFO] Saving to ./model/5.pth\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.480013\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.523159\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.524762\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.410458\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 8092/10000 (81%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.488403\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.365942\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.565057\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.333223\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 8310/10000 (83%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.360802\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.377406\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.360870\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.377731\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 8367/10000 (84%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.455451\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.409545\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.512702\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.394085\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 8264/10000 (83%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.454243\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.363173\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.430522\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.517625\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 8308/10000 (83%)\n",
      "\n",
      "[INFO] Saving to ./model/10.pth\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.480903\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.497947\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.471484\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.649709\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 7992/10000 (80%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.486499\n",
      "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.456781\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.361916\n",
      "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.457288\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 7766/10000 (78%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.484626\n",
      "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.354842\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.404652\n",
      "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.315021\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 8130/10000 (81%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.488203\n",
      "Train Epoch: 13 [16000/60000 (27%)]\tLoss: 0.483845\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.657723\n",
      "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.353538\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 8239/10000 (82%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.496786\n",
      "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.387645\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.527088\n",
      "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.411985\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 8164/10000 (82%)\n",
      "\n",
      "[INFO] Saving to ./model/15.pth\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.486370\n",
      "Train Epoch: 15 [16000/60000 (27%)]\tLoss: 0.421933\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.508301\n",
      "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.397260\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 7953/10000 (80%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.439575\n",
      "Train Epoch: 16 [16000/60000 (27%)]\tLoss: 0.533822\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.358635\n",
      "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.500955\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 8164/10000 (82%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.419223\n",
      "Train Epoch: 17 [16000/60000 (27%)]\tLoss: 0.408186\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.349728\n",
      "Train Epoch: 17 [48000/60000 (80%)]\tLoss: 0.418681\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 8268/10000 (83%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.441389\n",
      "Train Epoch: 18 [16000/60000 (27%)]\tLoss: 0.383884\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.394153\n",
      "Train Epoch: 18 [48000/60000 (80%)]\tLoss: 0.669946\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 8257/10000 (83%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.402797\n",
      "Train Epoch: 19 [16000/60000 (27%)]\tLoss: 0.374085\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.395750\n",
      "Train Epoch: 19 [48000/60000 (80%)]\tLoss: 0.527065\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 8290/10000 (83%)\n",
      "\n",
      "[INFO] Saving to ./model/20.pth\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "# 模型训练\n",
    "model.train(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = FashionMnistModel()\n",
    "# 加载权重\n",
    "state_dict = torch.load(\"./model/15.pth\")\n",
    "model2.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "\t\t\t\t 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, img):\n",
    "\tmodel.eval()\n",
    "\timg = img.unsqueeze(dim=0)\n",
    "\toutput = model(img)\n",
    "\tpred = output.argmax(dim=1, keepdim=True)\n",
    "\treturn pred.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9cf0926370>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset.__getitem__(100)\n",
    "pred = inference(model2, img)\n",
    "fig = plt.figure(figsize=(1, 1))\n",
    "plt.title(label_classes[pred])\n",
    "plt.imshow(np.squeeze(img), cmap='gray')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
